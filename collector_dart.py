import os, sys, time, tempfile, zipfile, io, threading, json, re
import requests, gspread
from datetime import datetime
import xml.etree.ElementTree as ET
from concurrent.futures import ThreadPoolExecutor, as_completed

# ===============================================
# CONFIG
# ===============================================
DART_API_KEY = "2577b83cd4832faf40689fb65ad1c51e34a1bfb3"   # ğŸ”¸ ë°˜ë“œì‹œ ë³¸ì¸ í‚¤ë¡œ êµì²´
FIN_SHEET = "fin_statement_quarter"
MAX_DAILY_CALLS = 30000
MAX_WORKERS = 6
DART_RPS = 4.0
TIMEOUT = 8
CHECKPOINT_FILE = "dart_checkpoint.json"
TREAT_OPERATING_REVENUE_AS_SALES = True  # ê¸ˆìœµì—… ëŒ€ì‘

# GitHub Actions í™˜ê²½ ë³€ìˆ˜ ë°˜ì˜
MAX_DAILY_CALLS = int(os.getenv("MAX_DAILY_CALLS", MAX_DAILY_CALLS))
SAMPLE_TICKERS = int(os.getenv("SAMPLE_TICKERS", "0"))  # 0ì´ë©´ ì „ì²´ ì¢…ëª©
FS_DIV_ONLY_CFS = os.getenv("FS_DIV_ONLY_CFS", "0") == "1"

SERVICE_ACCOUNT_JSON = os.environ.get("SERVICE_ACCOUNT_JSON")
SHEET_ID = os.environ.get("SHEET_ID")

# ===============================================
# HTTP + RateLimiter
# ===============================================
_session = requests.Session()
_session.headers.update({"User-Agent": "dart-collector/3.0"})
_token_lock = threading.Lock()
_tokens = DART_RPS
_last_refill = time.time()

def _acquire_token():
    global _tokens, _last_refill
    while True:
        with _token_lock:
            now = time.time()
            elapsed = now - _last_refill
            _tokens = min(DART_RPS, _tokens + elapsed * DART_RPS)
            _last_refill = now
            if _tokens >= 1.0:
                _tokens -= 1.0
                return
        time.sleep(0.02)

def _get_with_retry(url, params, max_retry=3):
    backoff = 0.5
    for _ in range(max_retry):
        _acquire_token()
        try:
            resp = _session.get(url, params=params, timeout=TIMEOUT)
            if resp.status_code == 200:
                return resp
        except:
            pass
        time.sleep(backoff)
        backoff *= 2
    return None

# ===============================================
# Google Sheet
# ===============================================
def open_sheet():
    if not SERVICE_ACCOUNT_JSON or not SHEET_ID:
        raise RuntimeError("ENV missing")
    with tempfile.NamedTemporaryFile(mode="w", suffix=".json", delete=False) as fp:
        fp.write(SERVICE_ACCOUNT_JSON)
        sa_path = fp.name
    gc = gspread.service_account(filename=sa_path)
    return gc.open_by_key(SHEET_ID)

_write_lock = threading.Lock()
def append_rows_safe(ws, rows, tag=""):
    if not rows: return
    with _write_lock:
        ws.append_rows(rows, value_input_option="RAW")
    print(f"[SAVE] {len(rows)} rows ({tag})", flush=True)

# ===============================================
# Checkpoint ê¸°ëŠ¥
# ===============================================
def save_checkpoint(done_list):
    with open(CHECKPOINT_FILE, "w", encoding="utf-8") as f:
        json.dump(list(done_list), f)

def load_checkpoint():
    if not os.path.exists(CHECKPOINT_FILE):
        return set()
    with open(CHECKPOINT_FILE, encoding="utf-8") as f:
        return set(json.load(f))

# ===============================================
# corpCode Map
# ===============================================
def get_corp_code_map():
    url = "https://opendart.fss.or.kr/api/corpCode.xml"
    resp = _session.get(url, params={"crtfc_key": DART_API_KEY}, timeout=20)
    with zipfile.ZipFile(io.BytesIO(resp.content)) as z:
        xml_data = z.read(z.namelist()[0])
    root = ET.fromstring(xml_data)
    mapping = {}
    for item in root.findall("list"):
        corp_code = item.findtext("corp_code", "").strip()
        stock_code = item.findtext("stock_code", "").strip()
        if stock_code and len(stock_code) == 6:
            mapping[stock_code] = corp_code
    print(f"[corpCode] Loaded {len(mapping)} companies")
    return mapping

# ===============================================
# ì¬ë¬´ ë°ì´í„° ë§¤í•‘
# ===============================================
REVENUE_IDS = {
    "ifrs-full_Revenue","ifrs_Revenue","dart_Revenue","dart_SalesRevenue",
    "ifrs-full_RevenueFromContractsWithCustomers","ifrs_RevenueFromContractsWithCustomers"
}
OPERATING_INCOME_IDS = {"ifrs-full_OperatingIncomeLoss","dart_OperatingIncomeLoss"}
NET_INCOME_IDS = {
    "ifrs-full_ProfitLoss","dart_NetIncomeLoss","ifrs-full_ProfitLossAttributableToOwnersOfParent"
}
ASSETS_IDS = {"ifrs-full_Assets"}
LIAB_IDS = {"ifrs-full_Liabilities"}
EQUITY_IDS = {"ifrs-full_Equity","ifrs-full_EquityAttributableToOwnersOfParent"}

REV_NAME_RE = re.compile(r"(ë§¤\s*ì¶œ|ë§¤ì¶œì•¡|ì˜ì—…ìˆ˜ìµ|ìƒí’ˆë§¤ì¶œ|ì œí’ˆë§¤ì¶œ)", re.I)
OP_NAME_RE  = re.compile(r"(ì˜ì—…\s*ì´ìµ|ì˜ì—…ì´ìµ\(ì†ì‹¤\)|ì˜ì—…ì†ì‹¤)", re.I)
NI_NAME_RE  = re.compile(r"(ë‹¹ê¸°\s*ìˆœ\s*ì´ìµ|ë¶„ê¸°\s*ìˆœ\s*ì´ìµ|ë‹¹ê¸°ìˆœì†ìµ)", re.I)
AS_NAME_RE  = re.compile(r"(ìì‚°\s*ì´ê³„|ìì‚°$)", re.I)
LI_NAME_RE  = re.compile(r"(ë¶€ì±„\s*ì´ê³„|ë¶€ì±„$)", re.I)
EQ_NAME_RE  = re.compile(r"(ìê¸°\s*ìë³¸|ìë³¸\s*ì´ê³„|ì§€ë°°ê¸°ì—…ì˜ì†Œìœ ì£¼ì§€ë¶„)", re.I)

def _parse_amount(v):
    if v is None: return None
    s = str(v).replace(",", "").strip()
    if s in {"", "-", "â€“"}: return None
    try: return int(float(s))
    except: return None

def _pick_by_id_or_name(items, id_set, name_re, used):
    for it in items:
        aid = (it.get("account_id") or it.get("account_cd") or "").strip()
        if aid and aid in id_set and f"id:{aid}" not in used:
            val = _parse_amount(it.get("thstrm_amount"))
            if val is not None: return val, f"id:{aid}"
    for it in items:
        nm = (it.get("account_nm") or "").strip()
        if name_re.search(nm) and f"nm:{nm}" not in used:
            val = _parse_amount(it.get("thstrm_amount"))
            if val is not None: return val, f"nm:{nm}"
    return None, None

def fetch_financials(corp_code, year, reprt_code):
    url = "https://opendart.fss.or.kr/api/fnlttSinglAcntAll.json"
    for fs_div in ("CFS", "OFS"):
        params = {
            "crtfc_key": DART_API_KEY,
            "corp_code": corp_code,
            "bsns_year": year,
            "reprt_code": reprt_code,
            "fs_div": fs_div,
        }
        resp = _get_with_retry(url, params)
        if not resp: continue
        data = resp.json()
        if data.get("status") != "000": continue
        items = data.get("list") or []
        if not items: continue

        used = set()
        revenue, rk = _pick_by_id_or_name(items, REVENUE_IDS, REV_NAME_RE, used)
        if revenue is None and TREAT_OPERATING_REVENUE_AS_SALES:
            revenue, rk = _pick_by_id_or_name(items, set(), re.compile(r"(ì˜ì—…ìˆ˜ìµ|ì´ììˆ˜ìµ|ë³´í—˜ë£Œìˆ˜ìµ)", re.I), used)
        if rk: used.add(rk)
        op, ok = _pick_by_id_or_name(items, OPERATING_INCOME_IDS, OP_NAME_RE, used);  used.add(ok or "")
        ni, nk = _pick_by_id_or_name(items, NET_INCOME_IDS, NI_NAME_RE, used);         used.add(nk or "")
        at, ak = _pick_by_id_or_name(items, ASSETS_IDS, AS_NAME_RE, used);             used.add(ak or "")
        li, lk = _pick_by_id_or_name(items, LIAB_IDS, LI_NAME_RE, used);               used.add(lk or "")
        eq, ek = _pick_by_id_or_name(items, EQUITY_IDS, EQ_NAME_RE, used);             used.add(ek or "")

        return {
            "ë§¤ì¶œì•¡": revenue or 0, "ì˜ì—…ì´ìµ": op or 0, "ë‹¹ê¸°ìˆœì´ìµ": ni or 0,
            "ìì‚°ì´ê³„": at or 0, "ë¶€ì±„ì´ê³„": li or 0, "ìê¸°ìë³¸": eq or 0
        }
    return {"ë§¤ì¶œì•¡":0,"ì˜ì—…ì´ìµ":0,"ë‹¹ê¸°ìˆœì´ìµ":0,"ìì‚°ì´ê³„":0,"ë¶€ì±„ì´ê³„":0,"ìê¸°ìë³¸":0}

# ===============================================
# ë¶„ê¸° ë‹¨í’ˆ ê³„ì‚°
# ===============================================
def _v(d, key): return int(d.get(key, 0) or 0)
def _sub(a,b): return max(0,a-b)

def make_quarter_single(series):
    Q1, H1, Q3, AN = [series.get(x,{}) for x in ("Q1","H1","Q3","ANNUAL")]
    return {
        "Q1": {"ë§¤ì¶œì•¡":_v(Q1,"ë§¤ì¶œì•¡"), "ì˜ì—…ì´ìµ":_v(Q1,"ì˜ì—…ì´ìµ"), "ë‹¹ê¸°ìˆœì´ìµ":_v(Q1,"ë‹¹ê¸°ìˆœì´ìµ"),
               "ìê¸°ìë³¸":_v(Q1,"ìê¸°ìë³¸"), "ë¶€ì±„ì´ê³„":_v(Q1,"ë¶€ì±„ì´ê³„"), "ìì‚°ì´ê³„":_v(Q1,"ìì‚°ì´ê³„")},
        "Q2": {"ë§¤ì¶œì•¡":_sub(_v(H1,"ë§¤ì¶œì•¡"),_v(Q1,"ë§¤ì¶œì•¡")), "ì˜ì—…ì´ìµ":_sub(_v(H1,"ì˜ì—…ì´ìµ"),_v(Q1,"ì˜ì—…ì´ìµ")),
               "ë‹¹ê¸°ìˆœì´ìµ":_sub(_v(H1,"ë‹¹ê¸°ìˆœì´ìµ"),_v(Q1,"ë‹¹ê¸°ìˆœì´ìµ")),
               "ìê¸°ìë³¸":_v(H1,"ìê¸°ìë³¸"), "ë¶€ì±„ì´ê³„":_v(H1,"ë¶€ì±„ì´ê³„"), "ìì‚°ì´ê³„":_v(H1,"ìì‚°ì´ê³„")},
        "Q3": {"ë§¤ì¶œì•¡":_sub(_v(Q3,"ë§¤ì¶œì•¡"),_v(H1,"ë§¤ì¶œì•¡")), "ì˜ì—…ì´ìµ":_sub(_v(Q3,"ì˜ì—…ì´ìµ"),_v(H1,"ì˜ì—…ì´ìµ")),
               "ë‹¹ê¸°ìˆœì´ìµ":_sub(_v(Q3,"ë‹¹ê¸°ìˆœì´ìµ"),_v(H1,"ë‹¹ê¸°ìˆœì´ìµ")),
               "ìê¸°ìë³¸":_v(Q3,"ìê¸°ìë³¸"), "ë¶€ì±„ì´ê³„":_v(Q3,"ë¶€ì±„ì´ê³„"), "ìì‚°ì´ê³„":_v(Q3,"ìì‚°ì´ê³„")},
        "Q4": {"ë§¤ì¶œì•¡":_sub(_v(AN,"ë§¤ì¶œì•¡"),_v(Q3,"ë§¤ì¶œì•¡")), "ì˜ì—…ì´ìµ":_sub(_v(AN,"ì˜ì—…ì´ìµ"),_v(Q3,"ì˜ì—…ì´ìµ")),
               "ë‹¹ê¸°ìˆœì´ìµ":_sub(_v(AN,"ë‹¹ê¸°ìˆœì´ìµ"),_v(Q3,"ë‹¹ê¸°ìˆœì´ìµ")),
               "ìê¸°ìë³¸":_v(AN,"ìê¸°ìë³¸"), "ë¶€ì±„ì´ê³„":_v(AN,"ë¶€ì±„ì´ê³„"), "ìì‚°ì´ê³„":_v(AN,"ìì‚°ì´ê³„")},
    }

# ===============================================
# ë©”ì¸ ìˆ˜ì§‘ (ìë™ ì¬ê°œ í¬í•¨)
# ===============================================
def collect_financials():
    sheet = open_sheet()
    try:
        ws = sheet.worksheet(FIN_SHEET)
    except:
        ws = sheet.add_worksheet(title=FIN_SHEET, rows=10, cols=15)
    if ws.row_values(1)[:1] != ["ticker"]:
        ws.insert_row(["ticker","corp_code","year","quarter","date","ë§¤ì¶œì•¡","ì˜ì—…ì´ìµ","ë‹¹ê¸°ìˆœì´ìµ","ìê¸°ìë³¸","ë¶€ì±„ì´ê³„","ìì‚°ì´ê³„"], 1)

    corp_map = get_corp_code_map()
    current_year = datetime.now().year
    years = [str(current_year-1), str(current_year)]
    quarters = [("11013","Q1"),("11012","H1"),("11014","Q3"),("11011","ANNUAL")]
    tasks = [(t,c,y,rc,qn) for t,c in corp_map.items() for y in years for rc,qn in quarters]
    print(f"[TASKS] {len(tasks)}")

    done = load_checkpoint()
    acc = {}
    api_calls = 0
    done_today = set()

    def worker(task):
        nonlocal api_calls
        ticker, corp_code, year, reprt_code, q_name = task
        key = f"{ticker}-{year}-{q_name}"
        if key in done or api_calls >= MAX_DAILY_CALLS:
            return None
        fin = fetch_financials(corp_code, year, reprt_code)
        api_calls += 1
        done_today.add(key)
        return (ticker, corp_code, year, q_name, fin)

    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as ex:
        for res in ex.map(worker, tasks):
            if api_calls >= MAX_DAILY_CALLS:
                print(f"[LIMIT] Hit {MAX_DAILY_CALLS}, saving checkpoint and exiting.")
                break
            if res:
                ticker, corp_code, year, q_name, fin = res
                acc.setdefault((ticker,year),{"corp_code":corp_code}).update({q_name:fin})

    save_checkpoint(done.union(done_today))

    # Q1~Q4 ê³„ì‚° ë° ì‹œíŠ¸ ì €ì¥
    print("[STEP] Calculating quarter singles...")
    rows = []
    for (ticker,year), s in acc.items():
        corp_code = s.get("corp_code","")
        singles = make_quarter_single(s)
        for q in ["Q1","Q2","Q3","Q4"]:
            fin = singles[q]
            rows.append([ticker,corp_code,year,q,f"{year}-{q}",
                         fin["ë§¤ì¶œì•¡"],fin["ì˜ì—…ì´ìµ"],fin["ë‹¹ê¸°ìˆœì´ìµ"],
                         fin["ìê¸°ìë³¸"],fin["ë¶€ì±„ì´ê³„"],fin["ìì‚°ì´ê³„"]])
    if rows:
        append_rows_safe(ws, rows, "quarter-singles")
    print(f"[DONE] {len(rows)} rows saved | API calls today: {api_calls}")

if __name__ == "__main__":
    collect_financials()
